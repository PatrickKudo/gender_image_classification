{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oEx-QDmMBZe",
        "outputId": "2950ae58-dd73-42af-dcc0-b136365b7c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## Basic imports \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCsmHzTdMOBV",
        "outputId": "6096503e-29c2-470c-b8a3-3bd5adc9e73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47035 images belonging to 2 classes.\n",
            "Found 11643 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 76, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import keras \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'gender_images/'\n",
        "\n",
        "os.chdir(base_dir)\n",
        "os.listdir()\n",
        "\n",
        "path_training = 'Training/'\n",
        "path_validation = 'Validation/'\n",
        "\n",
        "pic_path = path_training+'female/131435.jpg.jpg'\n",
        "image_size = (90, 90)\n",
        "batch_size = 128\n",
        "\n",
        "target_size = (224, 224)\n",
        "input_shape=(224, 224, 3)\n",
        "min_lr = 0.0001\n",
        "steps_per_epoch=256\n",
        "validation_steps=256\n",
        "epochs=8\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "      rotation_range=25,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    path_training,\n",
        "    validation_split = 0.2,\n",
        "    seed=10,\n",
        "    target_size=(98,76),\n",
        "    batch_size=batch_size,\n",
        "    classes=['female','male'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    path_validation,\n",
        "    seed=10,\n",
        "    target_size=(98,76),\n",
        "    batch_size=batch_size,\n",
        "    classes=['female','male'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from matplotlib.image import imread\n",
        "\n",
        "takeapeak = imread(pic_path)\n",
        "takeapeak.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x_myYjO3yCUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##print(\"Image size of train \",train_generator[0].shape)"
      ],
      "metadata": {
        "id": "vnYkB6B-xQE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5UUnQOYoGZ",
        "outputId": "55008ff9-6d95-4eb0-a6b4-a132cb41ed16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f7d1767e410> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d85860790> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d85872290> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f7d87ab1d50> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14cd44d0> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14ce24d0> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f7d14ce2750> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14de0ad0> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14cc6350> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14ce5510> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f7d14ce5110> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14cd4410> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14c7cf10> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14c812d0> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f7d14c81850> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14c8ba90> True\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14c97d90> True\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f7d14c97f50> True\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f7d14c97ed0> True\n",
            "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f7d14c94ed0> True\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,781,122\n",
            "Trainable params: 7,145,602\n",
            "Non-trainable params: 7,635,520\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers.optimizer_v2.rmsprop import RMSProp\n",
        "## Build the VGG model \n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Sequential,load_model,save_model\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "vgg=keras.applications.VGG16(include_top=False, pooling='avg', weights='imagenet',\n",
        "input_shape=(98,76, 3))\n",
        "\n",
        "\n",
        "# Freeze the layers except the last 5\n",
        "for layer in vgg.layers[:-5]:\n",
        " layer.trainable = False# Check the trainable status of the individual layers\n",
        "for layer in vgg.layers:\n",
        " print(layer, layer.trainable)\n",
        "\n",
        " # Create the model\n",
        "model = Sequential()# Add the VGG16 convolutional base model\n",
        "model.add(vgg)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "## Compile and Summary\n",
        "##model.compile(optimizer=Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer=RMSProp(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2gpkNqUYpL8",
        "outputId": "f0c1f54f-61b5-4db2-df68-292e231d6202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9258 \n",
            "Epoch 1: accuracy improved from -inf to 0.92578, saving model to best_tune_model.h5\n",
            "2/2 [==============================] - 132s 93s/step - loss: 0.1797 - accuracy: 0.9258\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9258 \n",
            "Epoch 2: accuracy did not improve from 0.92578\n",
            "2/2 [==============================] - 64s 24s/step - loss: 0.2128 - accuracy: 0.9258\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9258 \n",
            "Epoch 3: accuracy did not improve from 0.92578\n",
            "2/2 [==============================] - 73s 32s/step - loss: 0.1659 - accuracy: 0.9258\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "model_with_tuning = 'best_tune_model.h5'\n",
        "checkpoint_callback = ModelCheckpoint(model_with_tuning,\n",
        "                                     monitor='accuracy',\n",
        "                                      verbose=2,\n",
        "                                     save_best_only=True,mode='max')\n",
        "\n",
        "history_with_tuning = model.fit(train_generator,\n",
        "                   steps_per_epoch=len(train_generator) // 128,\n",
        "                   epochs=3,\n",
        "                   validation_data=validation_generator,\n",
        "                   validation_steps=len(validation_generator)// 128,\n",
        "                   verbose=1,\n",
        "                   callbacks=[checkpoint_callback])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYbkwlKMT8xY",
        "outputId": "d91b13ec-43bb-49e6-9412-1a4ef73d505a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r   1/1000 [..............................] - ETA: 24:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1000/1000 [==============================] - 2s 919us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# obtain predicted activation values for the last dense layer\n",
        "path_test = 'Test/'\n",
        "test1_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "test_generator = test1_datagen.flow_from_directory(\n",
        "    path_test,\n",
        "    seed=10,\n",
        "    target_size=(98,76),\n",
        "    batch_size=batch_size,\n",
        "    classes=['female','male'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "pred = model.predict_generator(test_generator, verbose=1, steps=1000)# determine the maximum activation value for each sample\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZP2EfiwGcZq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}